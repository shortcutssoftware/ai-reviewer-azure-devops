trigger: none

pr:
  branches:
    include:
    - main
  autoCancel: false

pool: 'ols-analysis'

variables:
  - group: 'Common Variables'
  - name: 'Model'
    value: 'claude-3-7-sonnet-20250219'
  - name: 'ModelVersion'
    value: '2023-06-01'
  - name: 'Organization'
    value: '<your_organization>'
  - name: 'Project'
    value: '<your_project>'
  - name: 'ProjectID'
    value: '<your_project_id>'

steps:
  - task: PowerShell@2
    displayName: Login into azure devops powershell
    inputs:
      targetType: 'inline'
      script: |
        az devops logout
        $repo = Split-Path -Leaf $(System.PullRequest.SourceRepositoryURI)
        echo $repo

        az config set extension.use_dynamic_install=yes_without_prompt
        echo $(System.AccessToken) | az devops login

        $repositoryId = $(az repos list --organization "$(Organization)" --project "$(Project)" --query "[?name == '$repo'].id" --output tsv)
        echo $repositoryId

        Write-Host "##vso[task.setvariable variable=repositoryId]$repositoryId"
        Write-Host "##vso[task.setvariable variable=repo]$repo"

  - task: Bash@3
    displayName: 'Clone repo'
    inputs:
      targetType: 'inline'
      script: |
        echo $(repo)

        rm -rf $(repo)
        echo "removed repo if existed"

        git -c http.extraHeader="Authorization: Bearer $(System.AccessToken)" clone $(System.PullRequest.SourceRepositoryURI)
        
        echo "successfully pulled new repo"
        
        cd $(repo)
        echo "Successfully cloned repository"
      workingDirectory: '$(Pipeline.Workspace)'

  - task: Bash@3
    displayName: 'build PR diff'
    inputs:
      targetType: 'inline'
      script: |
        SOURCE_BRANCH=$(echo $(System.PullRequest.SourceBranch) | sed 's|refs/heads|remotes/origin|')
        TARGET_BRANCH=$(echo $(System.PullRequest.TargetBranch) | sed 's|refs/heads|remotes/origin|')
        
        cd $(repo)

        git -c http.extraHeader="Authorization: Bearer $(System.AccessToken)" fetch --all
        git -c http.extraHeader="Authorization: Bearer $(System.AccessToken)" diff $(echo $TARGET_BRANCH) $(echo $SOURCE_BRANCH) -U100 > diff.patch

      workingDirectory: '$(Pipeline.Workspace)'

  - task: Bash@3
    displayName: 'claude-3-7-sonnet-20250219 SCA'
    inputs:
      targetType: 'inline'
      script: |
        cd $(repo) || { echo "Error: Failed to enter repository directory"; exit 1; }

        SOURCE_BRANCH=$(echo $(System.PullRequest.SourceBranch) | sed 's|refs/heads|remotes/origin|')
        TARGET_BRANCH=$(echo $(System.PullRequest.TargetBranch) | sed 's|refs/heads|remotes/origin|')

        files=$(git -c http.extraHeader="Authorization: Bearer $(System.AccessToken)" diff $(echo $TARGET_BRANCH) $(echo $SOURCE_BRANCH) --name-only)
        echo $files

        # Create individual diff files for each changed file
        file_count=0
        for FILE in $files; do
              if [[ "$FILE" == *.cs || "$FILE" == *.java || "$FILE" == *.ts ]]; then
                echo "Analyzing $FILE"
                git -c http.extraHeader="Authorization: Bearer $(System.AccessToken)" diff -U100 $(echo $TARGET_BRANCH):$FILE $(echo $SOURCE_BRANCH):$FILE > "diff_${file_count}.patch"
                echo "$FILE" > "filename_${file_count}.txt"
                file_count=$((file_count + 1))
              fi
        done

        if [ $file_count -eq 0 ]; then
            echo "No .cs, .ts or .java file types found"
            exit 0
        fi

        echo "Found $file_count files to analyze"

        # Function to call Anthropic API for a single diff chunk
        call_anthropic_api() {
            local chunk_file="$1"
            local filename="$2"
            local chunk_num="$3"
            
            if [ ! -s "$chunk_file" ]; then
                echo "Skipping empty diff for $filename"
                return
            fi
            
            # Check if diff contains actual changes (not just whitespace)
            if ! grep -q "^[+-]" "$chunk_file"; then
                echo "No meaningful changes found in $filename"
                return
            fi
            
            jq -Rs --arg model "$(Model)" --arg filename "$filename" '
            {
              model: $model,
              max_tokens: 4000,
              messages: [
                    {
                    role: "user", 
                    content: "Review this git diff for file \($filename). Focus on critical issues, security vulnerabilities, bugs, and performance problems. Provide specific, actionable feedback prioritized by severity. Format your response with severity levels (CRITICAL, HIGH, MEDIUM, LOW) and be concise:\n\(.)"
                    }
                ]
            }' "$chunk_file" > "payload_${chunk_num}.json"

            # Make API call with error handling
            http_status=$(curl -s -w "%{http_code}" -X POST https://api.anthropic.com/v1/messages \
                -H "x-api-key: $(ANTHROPIC_API_KEY)" \
                -H "anthropic-version: $(ModelVersion)" \
                -H "content-type: application/json" \
                --data "@payload_${chunk_num}.json" -o "api_response_${chunk_num}.json")
            
            if [ "$http_status" -eq 200 ]; then
                jq -r '.content[0].text' "api_response_${chunk_num}.json" > "response_${chunk_num}.txt" 2>/dev/null
                if [ $? -eq 0 ] && [ -s "response_${chunk_num}.txt" ]; then
                    echo "## File: $filename" >> "detailed_response_${chunk_num}.txt"
                    cat "response_${chunk_num}.txt" >> "detailed_response_${chunk_num}.txt"
                    echo "" >> "detailed_response_${chunk_num}.txt"
                    echo "Successfully analyzed $filename"
                else
                    echo "Warning: Failed to parse API response for $filename"
                fi
            else
                echo "Warning: API request failed for $filename (HTTP $http_status)"
                # Create fallback response
                echo "## File: $filename" >> "detailed_response_${chunk_num}.txt"
                echo "‚ö†Ô∏è  Analysis unavailable for this file due to API error" >> "detailed_response_${chunk_num}.txt"
                echo "" >> "detailed_response_${chunk_num}.txt"
            fi
        }

        # Process each file separately to avoid token limits
        for i in $(seq 0 $((file_count - 1))); do
            if [ -f "diff_${i}.patch" ] && [ -f "filename_${i}.txt" ]; then
                filename=$(cat "filename_${i}.txt")
                echo "Processing chunk $i for file: $filename"
                call_anthropic_api "diff_${i}.patch" "$filename" "$i"
            fi
        done

        # Generate summary of all findings
        echo "Generating prioritized summary..."
        
        # Collect all individual responses for summary generation
        cat detailed_response_*.txt > all_responses.txt 2>/dev/null || echo "" > all_responses.txt
        
        if [ -s all_responses.txt ]; then
            # Count successful analyses
            analysis_count=$(ls detailed_response_*.txt 2>/dev/null | wc -l)
            echo "Successfully analyzed $analysis_count file(s)"
            
            # Create summary prompt
            jq -Rs --arg model "$(Model)" '
            {
              model: $model,
              max_tokens: 2000,
              messages: [
                    {
                    role: "user", 
                    content: "Based on the following code review findings from multiple files, create a prioritized executive summary. List the top 5-7 most critical issues that need immediate attention, ordered by severity and impact. Each item should be concise (1-2 lines) and actionable. Use this format:\n\n## üéØ Priority Issues Summary\n\n### Critical Issues\n- [Issue description with file reference]\n\n### High Priority\n- [Issue description with file reference]\n\n### Medium Priority\n- [Issue description with file reference]\n\nIf no critical issues are found, focus on the most important improvements. Input findings:\n\(.)"
                    }
                ]
            }' all_responses.txt > payload_summary.json

            # Generate summary with error handling
            summary_http_status=$(curl -s -w "%{http_code}" -X POST https://api.anthropic.com/v1/messages \
                -H "x-api-key: $(ANTHROPIC_API_KEY)" \
                -H "anthropic-version: $(ModelVersion)" \
                -H "content-type: application/json" \
                --data "@payload_summary.json" -o "api_summary_response.json")

            # Build final response with summary first, then detailed findings
            echo "# üìã AI Code Review Results" > response.txt
            echo "" >> response.txt
            
            if [ "$summary_http_status" -eq 200 ]; then
                jq -r '.content[0].text' "api_summary_response.json" > summary_response.txt 2>/dev/null
                if [ $? -eq 0 ] && [ -s summary_response.txt ]; then
                    cat summary_response.txt >> response.txt
                    echo "" >> response.txt
                    echo "---" >> response.txt
                    echo "" >> response.txt
                    echo "Summary generation completed successfully"
                else
                    echo "## üéØ Priority Issues Summary" >> response.txt
                    echo "" >> response.txt
                    echo "‚ö†Ô∏è  Unable to generate priority summary due to parsing error" >> response.txt
                    echo "" >> response.txt
                    echo "---" >> response.txt
                    echo "" >> response.txt
                fi
            else
                echo "## üéØ Priority Issues Summary" >> response.txt
                echo "" >> response.txt
                echo "‚ö†Ô∏è  Unable to generate priority summary due to API error (HTTP $summary_http_status)" >> response.txt
                echo "" >> response.txt
                echo "---" >> response.txt
                echo "" >> response.txt
            fi
            
            echo "## üìÑ Detailed File-by-File Analysis" >> response.txt
            echo "" >> response.txt
            cat all_responses.txt >> response.txt

            echo "Final response prepared with $(wc -l < response.txt) lines"
            cat response.txt
        else
            echo "No analysis results generated"
            echo "# üìã AI Code Review Results" > response.txt
            echo "" >> response.txt
            echo "‚ö†Ô∏è  No reviewable changes found in supported file types (.cs, .java, .ts)" >> response.txt
        fi

      workingDirectory: '$(Pipeline.Workspace)'

  - task: Bash@3
    displayName: 'Create a PR Commment'
    inputs:
      targetType: 'inline'
      script: |

        cd $(repo) || { echo "Error: Failed to enter repository directory"; exit 1; }

        uri="$(Organization)/$(ProjectID)/_apis/git/repositories/$(repositoryId)/pullRequests/$(System.PullRequest.PullRequestId)/threads"
        content=$(cat response.txt)

        body=$(jq -n \
          --arg content "$(cat response.txt)" \
          --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")" \
          '{
            "id": -1,
            "comments": [
              {
                "commentType": 1,
                "content": $content
              }
            ],
            "properties": {
              "Microsoft.TeamFoundation.Discussion.SupportsMarkdown": {
                "type": "System.Int32",
                "value": 1
              }
            },
            "lastUpdatedDate": $timestamp,
            "publishedDate": $timestamp,
            "status": 1
          }')

        curl -s -X POST "$uri" \
          -H "Authorization: Bearer $(System.AccessToken)" \
          -H "Accept: application/json;api-version=5.0-preview" \
          -H "Content-Type: application/json" \
          -d "$body" \
          --verbose
      workingDirectory: '$(Pipeline.Workspace)'

  - task: Bash@3
    displayName: 'Cleanup'
    inputs:
      targetType: 'inline'
      script: |
        rm -rf $(repo)
      workingDirectory: '$(Pipeline.Workspace)'